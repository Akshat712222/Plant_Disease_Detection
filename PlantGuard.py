import streamlit as st
from PIL import Image
import torch
import torch.nn.functional as F
from torchvision import transforms
import torch.nn as nn
import google.generativeai as genai

# Configure Gemini API
genai.configure(api_key="AIzaSyDKqEmYY8y3wOC82Yv4WDzneWUPcCxl94c")
model_gemini = genai.GenerativeModel('gemini-2.5-flash')

# ImageClassificationBase class
class ImageClassificationBase(nn.Module):
    def training_step(self, batch):
        images, labels = batch
        out = self(images)
        loss = F.cross_entropy(out, labels)
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)
        loss = F.cross_entropy(out, labels)
        acc = accuracy(out, labels)
        return {"val_loss": loss.detach(), "val_accuracy": acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x["val_loss"] for x in outputs]
        batch_accuracy = [x["val_accuracy"] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()
        epoch_accuracy = torch.stack(batch_accuracy).mean()
        return {"val_loss": epoch_loss, "val_accuracy": epoch_accuracy}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))

# Conv Block
def ConvBlock(in_channels, out_channels, pool=False):
    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(inplace=True)]
    if pool:
        layers.append(nn.MaxPool2d(4))
    return nn.Sequential(*layers)

# ResNet9 Architecture
class ResNet9(ImageClassificationBase):
    def __init__(self, in_channels, num_diseases):
        super().__init__()
        self.conv1 = ConvBlock(in_channels, 64)
        self.conv2 = ConvBlock(64, 128, pool=True)
        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))
        self.conv3 = ConvBlock(128, 256, pool=True)
        self.conv4 = ConvBlock(256, 512, pool=True)
        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))
        self.classifier = nn.Sequential(
            nn.MaxPool2d(4),
            nn.Flatten(),
            nn.Linear(512, num_diseases)
        )

    def forward(self, xb):
        out = self.conv1(xb)
        out = self.conv2(out)
        out = self.res1(out) + out
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.res2(out) + out
        out = self.classifier(out)
        return out

# Class names
class_names = [
    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',
    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',
    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',
    'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot',
    'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',
    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',
    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',
    'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',
    'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy',
    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold',
    'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite',
    'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',
    'Tomato___Tomato_mosaic_virus', 'Tomato___healthy'
]

# Image transform
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# Prediction
def predict_image(img, model):
    img = img.convert("RGB")
    tensor = transform(img).unsqueeze(0).to(device)
    with torch.no_grad():
        outputs = model(tensor)
        _, predicted = torch.max(outputs, 1)
        return class_names[predicted.item()]

# Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load model
model = ResNet9(in_channels=3, num_diseases=len(class_names))
model.load_state_dict(torch.load("plant-disease-model.pth", map_location=device))
model.to(device)
model.eval()

# ===== Streamlit UI =====
st.set_page_config(
    page_title="PlantGuard",
    page_icon="üåø",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding: 2rem;
        border-radius: 10px;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
        border-radius: 5px;
        padding: 0.5rem;
    }
    .upload-text {
        font-size: 1.2rem;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    .success-box {
        padding: 1.5rem;
        border-radius: 5px;
        background-color: #e8f5e9;
        border-left: 5px solid #4CAF50;
        font-size: 1.1rem;
        color: #1b5e20;
        margin: 1rem 0;
    }
    .info-box {
        padding: 1.5rem;
        border-radius: 5px;
        background-color: #e3f2fd;
        border-left: 5px solid #2196F3;
        font-size: 1.1rem;
        color: #0d47a1;
        margin: 1rem 0;
        line-height: 1.6;
    }
    h3 {
        color: #2c3e50;
        font-size: 1.5rem;
        font-weight: 600;
        margin: 1.5rem 0 1rem 0;
    }
    .result-text {
        font-size: 1.2rem;
        font-weight: 500;
        color: #1b5e20;
    }
    .treatment-text {
        font-size: 1.1rem;
        line-height: 1.6;
        color: #0d47a1;
    }
    </style>
    """, unsafe_allow_html=True)

# Initialize default language
if 'language' not in st.session_state:
    st.session_state.language = 'English'
lang = st.session_state.language

# Translation UI strings
UI_TRANSLATIONS = {
    "English": {
        "title": "üåø PlantGuard",
        "upload_text": "Upload a plant leaf image to detect diseases and get instant care recommendations.",
        "language_settings": "Language Settings",
        "choose_language": "Choose your preferred language",
        "statistics": "Statistics",
        "diseases_detectable": "Diseases Detectable",
        "accuracy": "Accuracy",
        "quick_tips": "Quick Tips",
        "tips_content": "‚Ä¢ Ensure good lighting\n‚Ä¢ Center the leaf in image\n‚Ä¢ Use clear, focused shots",
        "upload_image": "Upload Image",
        "analysis_results": "Analysis Results",
        "analyzing": "Analyzing your plant...",
        "detected_condition": "Detected Condition:",
        "treatment_guide": "Treatment & Care Guide",
        "footer": "Powered by PlantGuard AI ‚Ä¢ Protecting Plants, Empowering Farmers"
    },
    "Hindi": {
        "title": "üåø ‡§™‡•ç‡§≤‡§æ‡§Ç‡§ü‡§ó‡§æ‡§∞‡•ç‡§°",
        "upload_text": "‡§∞‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§î‡§∞ ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ï‡•Ä ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂‡•á‡§Ç ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•å‡§ß‡•á ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡•Ä ‡§ï‡•Ä ‡§õ‡§µ‡§ø ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç‡•§",
        "language_settings": "‡§≠‡§æ‡§∑‡§æ ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏",
        "choose_language": "‡§Ö‡§™‡§®‡•Ä ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
        "statistics": "‡§Ü‡§Ç‡§ï‡§°‡§º‡•á",
        "diseases_detectable": "‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§∞‡•ã‡§ó",
        "accuracy": "‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ",
        "quick_tips": "‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§∏‡•Å‡§ù‡§æ‡§µ",
        "tips_content": "‚Ä¢ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§∞‡•ã‡§∂‡§®‡•Ä ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç\n‚Ä¢ ‡§™‡§§‡•ç‡§§‡•Ä ‡§ï‡•ã ‡§õ‡§µ‡§ø ‡§ï‡•á ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡•á‡§Ç\n‚Ä¢ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü, ‡§´‡•ã‡§ï‡§∏ ‡§ï‡•Ä ‡§ó‡§à ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç",
        "upload_image": "‡§õ‡§µ‡§ø ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "analysis_results": "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ",
        "analyzing": "‡§Ü‡§™‡§ï‡•á ‡§™‡•å‡§ß‡•á ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "detected_condition": "‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§à ‡§ó‡§à ‡§∏‡•ç‡§•‡§ø‡§§‡§ø:",
        "treatment_guide": "‡§â‡§™‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ó‡§æ‡§á‡§°",
        "footer": "‡§™‡•ç‡§≤‡§æ‡§Ç‡§ü‡§ó‡§æ‡§∞‡•ç‡§° AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‚Ä¢ ‡§™‡•å‡§ß‡•ã‡§Ç ‡§ï‡•Ä ‡§∞‡§ï‡•ç‡§∑‡§æ, ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§∂‡§ï‡•ç‡§§‡§ø‡§ï‡§∞‡§£"
    },
    "Marathi": {
        "title": "üåø ‡§™‡•ç‡§≤‡§æ‡§Ç‡§ü‡§ó‡§æ‡§∞‡•ç‡§°",
        "upload_text": "‡§∞‡•ã‡§ó ‡§∂‡•ã‡§ß‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§£‡§ø ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§ï‡§æ‡§≥‡§ú‡•Ä ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§Æ‡§ø‡§≥‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§®‡§∏‡•ç‡§™‡§§‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§™‡§æ‡§®‡§æ‡§ö‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§Æ‡§æ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡§æ.",
        "language_settings": "‡§≠‡§æ‡§∑‡§æ ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§ú",
        "choose_language": "‡§§‡•Å‡§Æ‡§ö‡•Ä ‡§™‡§∏‡§Ç‡§§‡•Ä‡§ö‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§®‡§ø‡§µ‡§°‡§æ",
        "statistics": "‡§Ü‡§ï‡§°‡•á‡§µ‡§æ‡§∞‡•Ä",
        "diseases_detectable": "‡§∂‡•ã‡§ß‡•Ç ‡§∂‡§ï‡§£‡§æ‡§∞‡•á ‡§∞‡•ã‡§ó",
        "accuracy": "‡§Ö‡§ö‡•Ç‡§ï‡§§‡§æ",
        "quick_tips": "‡§ú‡§≤‡§¶ ‡§ü‡§ø‡§™‡•ç‡§∏",
        "tips_content": "‚Ä¢ ‡§ö‡§æ‡§Ç‡§ó‡§≤‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂ ‡§Ö‡§∏‡§≤‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ñ‡§æ‡§§‡•ç‡§∞‡•Ä ‡§ï‡§∞‡§æ\n‚Ä¢ ‡§™‡§æ‡§® ‡§™‡•ç‡§∞‡§§‡§ø‡§Æ‡•á‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§ß‡•ç‡§Ø‡§≠‡§æ‡§ó‡•Ä ‡§†‡•á‡§µ‡§æ\n‚Ä¢ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü, ‡§´‡•ã‡§ï‡§∏ ‡§ï‡•á‡§≤‡•á‡§≤‡•á ‡§∂‡•â‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§™‡§∞‡§æ",
        "upload_image": "‡§™‡•ç‡§∞‡§§‡§ø‡§Æ‡§æ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡§æ",
        "analysis_results": "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§®‡§ø‡§ï‡§æ‡§≤",
        "analyzing": "‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§®‡§∏‡•ç‡§™‡§§‡•Ä‡§ö‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§ ‡§Ü‡§π‡•á...",
        "detected_condition": "‡§Ü‡§¢‡§≥‡§≤‡•á‡§≤‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä:",
        "treatment_guide": "‡§â‡§™‡§ö‡§æ‡§∞ ‡§Ü‡§£‡§ø ‡§ï‡§æ‡§≥‡§ú‡•Ä ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§ï",
        "footer": "‡§™‡•ç‡§≤‡§æ‡§Ç‡§ü‡§ó‡§æ‡§∞‡•ç‡§° AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡•á ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‚Ä¢ ‡§µ‡§®‡§∏‡•ç‡§™‡§§‡•Ä‡§Ç‡§ö‡•á ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§£, ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•á ‡§∏‡§ï‡•ç‡§∑‡§Æ‡•Ä‡§ï‡§∞‡§£"
    }
}

# Sidebar
with st.sidebar:
    st.image("logo.png", width=150)
    st.markdown("---")
    st.markdown(f"### üåê {UI_TRANSLATIONS[st.session_state.language]['language_settings']}")
    selected_lang = st.selectbox(
        UI_TRANSLATIONS[st.session_state.language]['choose_language'],
        ["English", "Hindi", "Marathi"],
        index=["English", "Hindi", "Marathi"].index(st.session_state.language),
        key="lang_selector"
    )
    
    # Update session state when language changes
    if selected_lang != st.session_state.language:
        st.session_state.language = selected_lang
        st.rerun()

    st.markdown("---")
    st.markdown(f"### üìä {UI_TRANSLATIONS[st.session_state.language]['statistics']}")
    st.metric(label=UI_TRANSLATIONS[st.session_state.language]['diseases_detectable'], value="38")
    st.metric(label=UI_TRANSLATIONS[st.session_state.language]['accuracy'], value="96%")
    st.markdown("---")
    st.markdown(f"### üí° {UI_TRANSLATIONS[st.session_state.language]['quick_tips']}")
    st.info(UI_TRANSLATIONS[st.session_state.language]['tips_content'])

# Main content
st.title(UI_TRANSLATIONS[st.session_state.language]['title'])
st.markdown(f"<p class='upload-text'>{UI_TRANSLATIONS[st.session_state.language]['upload_text']}</p>", unsafe_allow_html=True)

# Create two columns for upload and preview
col1, col2 = st.columns([1, 1])

with col1:
    st.markdown(f"### üì∏ {UI_TRANSLATIONS[st.session_state.language]['upload_image']}")
    uploaded_file = st.file_uploader("", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    with col1:
        st.image(image, caption=UI_TRANSLATIONS[st.session_state.language]['upload_image'], use_container_width=True)
    
    with col2:
        st.markdown(f"### üîç {UI_TRANSLATIONS[st.session_state.language]['analysis_results']}")
        with st.spinner(UI_TRANSLATIONS[st.session_state.language]['analyzing']):
            label = predict_image(image, model)
            st.markdown(
                f"""<div class='success-box'>
                    ‚úÖ <span class='result-text'>{UI_TRANSLATIONS[st.session_state.language]['detected_condition']}</span><br>
                    <strong style='font-size: 1.3rem;'>{label.replace('_', ' ')}</strong>
                </div>""", 
                unsafe_allow_html=True
            )
            
            # Generate explanation and solution
            eng_prompt = f"Give a simple explanation and solution for this plant disease: {label.replace('_', ' ')}"
            response = model_gemini.generate_content(eng_prompt)
            
            # Handle translation
            if lang in ["Hindi", "Marathi"]:
                translation_prompt = f"Translate the following text to {lang}:\n\n{response.text}"
                translated = model_gemini.generate_content(translation_prompt)
                final_response = translated.text
            else:
                final_response = response.text

            st.markdown(f"### üß™ {UI_TRANSLATIONS[st.session_state.language]['treatment_guide']}")
            st.markdown(
                f"""<div class='info-box'>
                    <span class='treatment-text'>{final_response}</span>
                </div>""", 
                unsafe_allow_html=True
            )

# Footer
st.markdown("---")
st.markdown(
    f"<div style='text-align: center; color: #666;'>{UI_TRANSLATIONS[st.session_state.language]['footer']}</div>",
    unsafe_allow_html=True
)
